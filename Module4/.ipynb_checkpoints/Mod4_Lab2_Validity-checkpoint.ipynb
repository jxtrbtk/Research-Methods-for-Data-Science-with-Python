{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module 4, Lab 2 - Validity\n",
    "==========================\n",
    "\n",
    "In this lab, we build on the previous lab to validate our measure of\n",
    "consumer sentiment. In the previous lab, we found that we could make a\n",
    "reliable, one-factor measure that we think represents consumer\n",
    "sentiment. However, we did not show that the measure was actually\n",
    "measuring sentiment. In this lab, we discuss the concept of measurement\n",
    "validity--ensuring that the measure actually captures what it claims to.\n",
    "\n",
    "There is no sure-fire way to ensure that a measure is valid. However,\n",
    "there are some things we can consider.\n",
    "\n",
    "1.  **Face validity:** does the measure look valid, at face level? This is\n",
    "    subjective, but it is important. For example, in the previous lab,\n",
    "    we captured people's feelings about a taco brand with reported\n",
    "    rating on four adjectives: \"inviting,\" \"friendly,\" \"awesome,\" and\n",
    "    \"pleasant.\" We asked people to rate how well each adjective\n",
    "    describes the brand on a 1-10 scale. We can think through whether\n",
    "    these seem like they would be capturing sentiment. Clearly, a person\n",
    "    who rates a brand highly on \"awesome\" feels positive toward the\n",
    "    brand, right? Well, we can think through this a bit more. What other\n",
    "    reasons might a person respond positively on that question? Might\n",
    "    they just be an enthusiastic person? Perhaps someone who wants to\n",
    "    make a good impression or feels social pressure from the survey to\n",
    "    give a positive response? Next, we might consider whether those\n",
    "    issues would be shared among all the adjectives. Indeed, it seems\n",
    "    possible. There are still some other issues we might consider. For\n",
    "    example, do people really know and have the ability to report their\n",
    "    attitudes and feelings toward a brand accurately? Might something\n",
    "    else such as an analysis of their natural language be better? In\n",
    "    short, this measure *looks* face valid, but can also conceive of\n",
    "    some potential threats to its validity. We then would have to ask\n",
    "    whether those issues are big enough to warrant not using it.\n",
    "\n",
    "2.  **Content validity:** does the measure have the appropriate breadth?\n",
    "    With this set of adjectives, we might consider other words that\n",
    "    should be included, or we might consider removing some that don't\n",
    "    belong. This is also subjective. Indeed, in the last lab we were\n",
    "    considering discarding \"quirky\" before the data analysis came in.\n",
    "\n",
    "3.  **Criterion validity:** does the variable correlate in ways that a good\n",
    "    measure should? This is the \"data-driven\" option, but it is not\n",
    "    without issues as well. For example, it presumes that you have\n",
    "    picked a good set of outcomes to correlate it with and that those\n",
    "    are also measured validly. Still, assuming you are collecting data,\n",
    "    it doesn't hurt to collect a little bit more or to check this in the\n",
    "    data that you have collected.\n",
    "\n",
    "In this lab, I briefly demonstrate **criteiron validity** by checking\n",
    "correlations among measures.\n",
    "\n",
    "Load Data\n",
    "=========\n",
    "\n",
    "In this lab, I use a slightly different measure of sentiment but a\n",
    "similar research design. A research team has a new sentiment measure,\n",
    "and they wish to know if it is criterion valid. To validate it, they\n",
    "have assembled data on the number of positive words used to describe a\n",
    "product (word count, or `WC`), the rating of a product using a standard\n",
    "rating system (`rating`), and the anticipated likelihood of purchase\n",
    "(`purchase`). The data are in the github folder for this lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LOAD DATA ####\n",
    "import pandas as pd\n",
    "dat = pd.read_csv(\"datasets/validity.csv\", index_col = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can briefly check the data. Notice there is an id variable called `X`\n",
    "as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent        int64\n",
      "WC          int64\n",
      "rating      int64\n",
      "purchase    int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>WC</th>\n",
       "      <th>rating</th>\n",
       "      <th>purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent  WC  rating  purchase\n",
       "1     5   3       5         2\n",
       "2    10   1       6         4\n",
       "3     8   2       7         3\n",
       "4     6   4       6         3\n",
       "5     9   2       7         4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dat.dtypes)\n",
    "\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the sentiment measure criterion valid? We can test this by simply\n",
    "assessing correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>WC</th>\n",
       "      <th>rating</th>\n",
       "      <th>purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WC</th>\n",
       "      <td>0.30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purchase</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sent    WC  rating  purchase\n",
       "sent      1.00  0.30    0.69      0.55\n",
       "WC        0.30  1.00    0.15      0.05\n",
       "rating    0.69  0.15    1.00      0.32\n",
       "purchase  0.55  0.05    0.32      1.00"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#correlations\n",
    "corr_mat = dat.corr().round(2)\n",
    "corr_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that the sentiment variable correlates at .30 with word\n",
    "count, .69 with a product rating, and .55 with purchase likelihood. We\n",
    "also see that those correlations are larger than they are between the\n",
    "other measures (e.g., the `rating` variable is not correlating more\n",
    "strongly with the other variables).\n",
    "\n",
    "We can easily compute the confidence intervals of these correlation coefficients. However, this requires a few steps which we first encountered in the Association lab:   \n",
    "1. Transform the correlation from the initial space which we call r to a transformed space z. The distribution of errors is Normal in this transformed space. \n",
    "2. Compute the CI in the transformed space.\n",
    "3. Transform back to the original space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For sent vs. WC\n",
      "Correlation = 0.300 with CI of 0.243 to 0.355\n",
      "\n",
      "For sent vs. rating\n",
      "Correlation = 0.690 with CI of 0.656 to 0.721\n",
      "\n",
      "For sent vs. purchase\n",
      "Correlation = 0.550 with CI of 0.505 to 0.592\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import math\n",
    "\n",
    "def r_z(r):\n",
    "    return math.log((1 + r) / (1 - r)) / 2.0\n",
    "\n",
    "def z_r(z):\n",
    "    e = math.exp(2 * z)\n",
    "    return((e - 1) / (e + 1))\n",
    "\n",
    "def r_conf_int(r, alpha, n):\n",
    "    # Transform r to z space\n",
    "    z = r_z(r)\n",
    "    # Compute standard error and critcal value in z\n",
    "    se = 1.0 / math.sqrt(n - 3)\n",
    "    z_crit = ss.norm.ppf(1 - alpha/2)\n",
    "\n",
    "    ## Compute CIs with transform to r\n",
    "    lo = z_r(z - z_crit * se)\n",
    "    hi = z_r(z + z_crit * se)\n",
    "    return (lo, hi)\n",
    "\n",
    "def print_cis(corr_mat,var1, var2, idx1, idx2):\n",
    "    print('\\nFor ' + var1 + ' vs. ' + var2)\n",
    "    conf_ints = r_conf_int(corr_mat[idx1,idx2], 0.05, 1000)\n",
    "    print('Correlation = %4.3f with CI of %4.3f to %4.3f' % (corr_mat[idx1,idx2], conf_ints[0], conf_ints[1]))\n",
    "\n",
    "corr_mat = np.array(corr_mat)\n",
    "\n",
    "print_cis(corr_mat, 'sent', 'WC', 1, 0)\n",
    "print_cis(corr_mat, 'sent', 'rating', 0, 2)\n",
    "print_cis(corr_mat, 'sent', 'purchase', 0, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the confidence intervals for correlations with sentiment are all small. It appears that all three correlations are significant.\n",
    "\n",
    "Although this is a short exercise, it is critically important. Not only\n",
    "can you quickly see if a measure is valid, but you might also find a\n",
    "better measure. For example, if the product rating was correlating with\n",
    "purchase likelihood *better* than the sentiment measure, I would\n",
    "question the use of the sentiment measure for making decisions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
